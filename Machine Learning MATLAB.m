function [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% Returns a trained classifier and its accuracy. This code recreates the
% classification model trained in Classification Learner app. Use the
% generated code to automate training the same model with new data, or to
% learn how to programmatically train models.
%
%  Input:
%      trainingData: A table containing the same predictor and response
%       columns as those imported into the app.
%
%  Output:
%      trainedClassifier: A struct containing the trained classifier. The
%       struct contains various fields with information about the trained
%       classifier.
%
%      trainedClassifier.predictFcn: A function to make predictions on new
%       data.
%
%      validationAccuracy: A double containing the accuracy in percent. In
%       the app, the History list displays this overall accuracy score for
%       each model.
%
% Use the code to train the model with new data. To retrain your
% classifier, call the function from the command line with your original
% data or new data as the input argument trainingData.
%
% For example, to retrain a classifier trained with the original data set
% T, enter:
%   [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
% To make predictions with the returned 'trainedClassifier' on new data T2,
% use
%   yfit = trainedClassifier.predictFcn(T2)
%
% T2 must be a table containing at least the same predictor columns as used
% during training. For details, enter:
%   trainedClassifier.HowToPredict
 
% Auto-generated by MATLAB on 16-Sep-2021 09:34:19
 
%%
% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
% Set up the Import Options and import the data
% replace 67 with the correct number of variables
opts = spreadsheetImportOptions("NumVariables", 67);
 
% replace EXCEL_FILE with the name of your excel file and A2:BO158 with the cell ranges from your excel file
% Specify sheet and range
opts.Sheet = "EXCEL_FILE";
opts.DataRange = "A2:BO158";
 
% Specify column names and types
% replace variable names with the names of your variables
opts.VariableNames = ["ID", "Predictor_1", "Predictor_2", "Predictor_3", "Outcome_variable"]; 
% replace double with the variable types and number of statements match the order of your variables
opts.VariableTypes = ["double", "double", "double", "double", "double"];
 
% Import the data
% replace "C:\Users\Documents\excel_files\excel_file.xlsx" with the location and name of your excel file
excel_file = readtable("C:\Users\Documents\excel_files\excel_file.xlsx", opts, "UseExcel", false);
trainingData = excel_file;
 
% Clear temporary variables
clear opts
 
% set seed to produce the same results each time
rng(1);
%%
inputTable = trainingData;
% replace variables with your predictors
predictorNames = {'Predictor_1', 'Predictor_2', 'Predictor_3'};  
predictors = inputTable(:, predictorNames);
response = inputTable.Outcome_variable;
% replace with variable type
isCategoricalPredictor = [false, false, false];
%%
% Train a classifier GNB
% This code specifies all the classifier options and trains the classifier.
 
% Expand the Distribution Names per predictor
% Numerical predictors are assigned either Gaussian or Kernel distribution and categorical predictors are assigned mvmn distribution
% Gaussian is replaced with Normal when passing to the fitcnb function
distributionNames =  repmat({'Normal'}, 1, length(isCategoricalPredictor));
distributionNames(isCategoricalPredictor) = {'mvmn'};
 
if any(strcmp(distributionNames,'Kernel'))
    classificationNaiveBayes = fitcnb(...
        predictors, ...
        response, ...
        'Kernel', 'Normal', ...
        'Support', 'Unbounded', ...
        'DistributionNames', distributionNames, ...
        'ClassNames', [0; 1]);
else
    classificationNaiveBayes = fitcnb(...
        predictors, ...
        response, ...
        'DistributionNames', distributionNames, ...
        'ClassNames', [0; 1]);
end
 
% Create the result struct with predict function
predictorExtractionFcn = @(t) t(:, predictorNames);
naiveBayesPredictFcn = @(x) predict(classificationNaiveBayes, x);
trainedClassifier.predictFcn = @(x) naiveBayesPredictFcn(predictorExtractionFcn(x));
 
% Add additional fields to the result struct
% replace with your predictor variables
trainedClassifier.RequiredVariables = {'Predictor_1', 'Predictor_2', 'Predictor_3'};
trainedClassifier.ClassificationNaiveBayes = classificationNaiveBayes;
trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2021a.';
trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');
 
% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
% replace with your predictor variables
predictorNames = {'Predictor_1', 'Predictor_2', 'Predictor_3'};
predictors = inputTable(:, predictorNames);
response = inputTable.Outcome_variable;
% replace with the type of your predictor variables
isCategoricalPredictor = [false, false, false];
 
% Perform cross-validation
partitionedModel = crossval(trainedClassifier.ClassificationNaiveBayes, 'KFold', 10);
 
% Compute validation predictions
[validationPredictions, validationScores] = kfoldPredict(partitionedModel);
 
% Compute validation accuracy
validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');
 
% Compute validation predictions and scores
[validationPredictions, validationScores] = kfoldPredict(partitionedModel);
%%
[Xgnb,Ygnb,~,AUCgnb] = perfcurve(partitionedModel.Y,validationScores(:,1),'0');
%%
plot(Xgnb,Ygnb)
xlabel('1 - Specificity') 
ylabel('Sensitivity')
title('ROC for Classification by GNB')
%%
AUCgnb
%%
Cgnb = confusionmat(partitionedModel.Y,validationPredictions);
CPgnb = classperf(partitionedModel.Y,validationPredictions);
%%
Cgnb
CPgnb
%%
for i = 1:10
  % Call index of testing set
  testIdx = partitionedModel.Partition.test(i);
  % Call testing labels
  ytest=partitionedModel.Y(testIdx);
  % get the trained model
  % Perform testing
  Pred0 = validationPredictions(testIdx); 
  % A=size(Pred0,1); 
  % Confusion matrix for each if wanted
  con = confusionmat(ytest,Pred0);
    % print it out if wanted
    % disp(['The Confusion matrix for fold number ' num2str(i)])
    % disp(con)
  % classperf
  D = classperf(ytest,Pred0);
  % Accuracy for each fold
  Accfold(i) = 100*(D.CorrectRate);  
  %Sensitivity for each fold
  Sensfold(i) = 100*(D.Sensitivity);
  %Specificity for each fold
  Specfold(i) = 100*(D.Specificity);
  Percfold(i) = 100*(con(1,1)/(con(1,1)+con(2,1)));
  % Store temporary
  %pred2=[pred2(1:end);Pred0]; ytest2=[ytest2(1:end);ytest];
end
%%
%trainedClassifier.predictFcn() = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');
disp('accuracy')
mean(Accfold)
std(Accfold)
disp('Sensitivity')
mean(Sensfold)
std(Sensfold)
disp('Specificity')
mean(Specfold)
std(Specfold)
disp('Precision')
mean(Percfold)
std(Percfold)
%%
clear all;
